{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate l-distance between two strings\n",
    "# accepts two string parameters: \n",
    "def ldistance(strA, strB):\n",
    "    import numpy as np # to create matrix\n",
    "    \n",
    "    a = 0\n",
    "    b = 0\n",
    "    c = 0\n",
    "    \n",
    "    #setting up matrix\n",
    "    size_x = len(strA) + 1\n",
    "    size_y = len(strB) + 1\n",
    "    matrix = np.zeros((size_x, size_y))\n",
    "    for x in range(size_x):\n",
    "        matrix [x, 0] = x\n",
    "    for y in range(size_y):\n",
    "        matrix [0, y] = y\n",
    "    \n",
    "    #populating matrix\n",
    "    for x in range(1, size_x):\n",
    "        for y in range(1, size_y):\n",
    "            if strA[x-1] == strB[y-1]: #elements are equal\n",
    "                matrix[x][y] = matrix[x-1][y-1]\n",
    "            else: \n",
    "                a = matrix[x][y-1]\n",
    "                b = matrix[x-1][y]\n",
    "                c = matrix[x-1][y-1]\n",
    "                if (a <= b and a <= c):\n",
    "                    matrix[x][y] = a + 1\n",
    "                elif (b <= a and b <= c):\n",
    "                    matrix[x][y] = b + 1\n",
    "                else:\n",
    "                    matrix[x][y] = c + 1\n",
    "        \n",
    "\n",
    "                    \n",
    "    # bottom-right element is l-distance\n",
    "    distance = matrix[-1][-1]\n",
    "    \n",
    "    # printing\n",
    "    #for t1 in range(size_x):\n",
    "        #for t2 in range(size_y ):\n",
    "            #print(int(matrix[t1][t2]), end=\" \")\n",
    "        #print()\n",
    "        \n",
    "    #taking into consideration the length of the words\n",
    "    length = 0\n",
    "    if ((len(strA) > len(strB)) or (len(strA) == len(strB))):\n",
    "        length = len(strA)\n",
    "    else:\n",
    "        length = len(strB)\n",
    "        \n",
    "    lscore = ((length - distance) / length) \n",
    "    \n",
    "    return lscore\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer \n",
    "from nltk.corpus import stopwords\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove vowels, common words, numbers, and punctuation, as well as stem the words\n",
    "# accepts 2 parameters: string for sample and string for language\n",
    "def clean_sample(sample, language):\n",
    "    import nltk \n",
    "    import re # to use in regular expressions\n",
    "    from nltk.stem.snowball import SnowballStemmer # to stem words, doesn't work well\n",
    "    from nltk.corpus import stopwords # to remove common words\n",
    "    \n",
    "    # creating objects for stemmer, common words and key for punctuation/numbers to be removed\n",
    "    stemmer = SnowballStemmer(str(language))\n",
    "    common_words = stopwords.words(language)\n",
    "    \n",
    "    if language == \"french\":\n",
    "        toRemove = re.compile(r\"[aeiou0-9,@\\?\\.$%_/:()l'd']\")\n",
    "    else:\n",
    "        toRemove = re.compile(r\"[aeiou0-9,@\\?\\.$%_/:()]\")\n",
    "\n",
    "    # separates sentence into elements and stores in elemList\n",
    "    elemList=sample.split()\n",
    "    \n",
    "    # stemming first\n",
    "    stems=[]\n",
    "    for elem in elemList:\n",
    "        if elem not in common_words:\n",
    "            w = stemmer.stem(elem)\n",
    "            stems.append(w)\n",
    "    \n",
    "    #now removing punctuation, numbers, vowels and storing in wordList\n",
    "    wordList=[]\n",
    "    for i in stems:\n",
    "        i = unidecode(i)\n",
    "        elem = re.sub(toRemove, \"\", i.lower())\n",
    "        print(i + \" \" + elem)\n",
    "        wordList.append(elem)\n",
    "    \n",
    "    # stems words and appends them to list to be returned\n",
    "    return wordList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that lines up pairs of words between the two samples, and calculates their l-distance\n",
    "# parameters: 2 lists of words from each sample, 1 list of manually-created alignment between the two lists\n",
    "def measure_samples(list1, list2, alignment):\n",
    "    distances=[]\n",
    "    \n",
    "    # aligning pairs\n",
    "    for i in range(len(alignment)):\n",
    "        idx1 = alignment[i][0]\n",
    "        idx2 = alignment[i][1]\n",
    "        str1 = list1[idx1]\n",
    "        str2 = list2[idx2]\n",
    "        print(str1 + \"-\" + str2)\n",
    "        l = ldistance(str(str1), str(str2))\n",
    "        distances.append(l)\n",
    "        \n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that lines up pairs of words between the two samples, and calculates their l-distance\n",
    "# parameters: 2 lists of words from each sample, 1 list of manually-created alignment between the two lists\n",
    "def measure_samples_dict(list1, list2, alignment):\n",
    "    distances=[]\n",
    "    \n",
    "    # aligning pairs\n",
    "    for i in alignment:\n",
    "        str2 = \"\"\n",
    "        str1 = list1[int(i)]\n",
    "        for x in range(len(ger_eng_dict[i])):\n",
    "            str2 += list2[alignment[i][x]]\n",
    "        print(str1 + \"-\" + str2)\n",
    "        l = ldistance(str(str1), str(str2))\n",
    "        distances.append(l)\n",
    "        \n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_c_dict(sample,language):\n",
    "    # initialize an empty dictionary\n",
    "    c_dict = {}\n",
    "    # strip the string input to only consonants\n",
    "    # first clean sample (returns a list), use join to turn to string\n",
    "    striped_c = (\"\").join(clean_sample(sample,language))\n",
    "    \n",
    "    # populate the dictionary\n",
    "    for c in striped_c:\n",
    "        if c in c_dict.keys():\n",
    "            # increment count\n",
    "            c_dict[c] +=1\n",
    "        else:\n",
    "            # add to consonant dict\n",
    "            c_dict[c] = 1\n",
    "    \n",
    "    return c_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guid gd\n",
      "purpos prps\n",
      "principl prncpl\n",
      "charter chrtr\n",
      "unit nt\n",
      "nations, ntns\n",
      "express xprss\n",
      "particular prtclr\n",
      "need nd\n",
      "achiev chv\n",
      "intern ntrn\n",
      "cooper cpr\n",
      "promot prmt\n",
      "encourag ncrg\n",
      "respect rspct\n",
      "human hmn\n",
      "right rght\n",
      "fundament fndmnt\n",
      "freedom frdm\n",
      "without wtht\n",
      "distinct dstnct\n",
      "inspir nspr\n",
      "proposit prpst\n",
      "principi prncp\n",
      "cart crt\n",
      "nacion ncn\n",
      "unid nd\n",
      "expres xprs\n",
      "particul prtcl\n",
      "neces ncs\n",
      "logr lgr\n",
      "cooper cpr\n",
      "internacional ntrncnl\n",
      "promocion prmcn\n",
      "foment fmnt\n",
      "respet rspt\n",
      "derech drch\n",
      "human hmn\n",
      "libertad lbrtd\n",
      "fundamental fndmntl\n",
      "distincion dstncn\n",
      "Spa-Eng Pairs\n",
      "\n",
      "gd-nspr\n",
      "prps-prpst\n",
      "prncpl-prncp\n",
      "chrtr-crt\n",
      "nt-nd\n",
      "ntns-ncn\n",
      "xprss-xprs\n",
      "prtclr-prtcl\n",
      "nd-ncs\n",
      "chv-lgr\n",
      "ntrn-ntrncnl\n",
      "cpr-cpr\n",
      "prmt-prmcn\n",
      "ncrg-fmnt\n",
      "rspct-rspt\n",
      "hmn-hmn\n",
      "rght-drch\n",
      "frdm-lbrtd\n",
      "fndmnt-fndmntl\n",
      "dstnct-dstncn\n",
      "\n",
      "\n",
      "English consonants\n",
      "\n",
      "['gd', 'prps', 'prncpl', 'chrtr', 'nt', 'ntns', 'xprss', 'prtclr', 'nd', 'chv', 'ntrn', 'cpr', 'prmt', 'ncrg', 'rspct', 'hmn', 'rght', 'fndmnt', 'frdm', 'wtht', 'dstnct']\n",
      "\n",
      "\n",
      "Spanish consonants\n",
      "\n",
      "['nspr', 'prpst', 'prncp', 'crt', 'ncn', 'nd', 'xprs', 'prtcl', 'ncs', 'lgr', 'cpr', 'ntrncnl', 'prmcn', 'fmnt', 'rspt', 'drch', 'hmn', 'lbrtd', 'fndmntl', 'dstncn']\n",
      "\n",
      "\n",
      "L-Distance measures per pair of aligned words\n",
      "\n",
      "[0.0, 0.8, 0.8333333333333334, 0.6, 0.5, 0.5, 0.8, 0.8333333333333334, 0.3333333333333333, 0.0, 0.5714285714285714, 1.0, 0.6, 0.0, 0.8, 1.0, 0.25, 0.2, 0.8571428571428571, 0.8333333333333334]\n",
      "\n",
      "\n",
      "Average\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.565595238095238"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#English and Spanish\n",
    "import nltk\n",
    "engSample = \"Guided by the purposes and principles of the Charter of the United Nations, and expressing in particular the need to achieve international cooperation in promoting and encouraging respect for human rights and fundamental freedoms for all without distinction\"\n",
    "spaSample = \"Inspirándose en los propósitos y principios de la Carta de las Naciones Unidas y expresando en particular la necesidad de lograr la cooperación internacional en la promoción y el fomento del respeto de los derechos humanos y las libertades fundamentales para todos sin distinción\"\n",
    "\n",
    "#Removing vowels, punctuation, stemming\n",
    "engWords = clean_sample(engSample, \"english\")\n",
    "spaWords = clean_sample(spaSample, \"spanish\")\n",
    "\n",
    "#Manually transcribing sentence alignment to compare word-to-word\n",
    "print(\"Spa-Eng Pairs\\n\")\n",
    "eng_spa_align = [(0,0), (1,1), (2,2), (3,3), (4,5), (5,4), (6, 6), (7,7), (8,8), (9,9), (10, 11), (11, 10), (12, 12), (13, 13), (14, 14), (15, 16), (16, 15), (18, 17), (17, 18), (20, 19)]\n",
    "\n",
    "#Passing lists of consonant-only words in both languages and their alignment to Ldistnance method\n",
    "measures = measure_samples(engWords, spaWords, eng_spa_align)\n",
    "print(\"\\n\")\n",
    "print(\"English consonants\\n\")\n",
    "print(engWords)\n",
    "print(\"\\n\")\n",
    "print(\"Spanish consonants\\n\")\n",
    "print(spaWords)\n",
    "print(\"\\n\")\n",
    "print(\"L-Distance measures per pair of aligned words\\n\")\n",
    "print(measures)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Average\")\n",
    "avg = 0\n",
    "for i in range(len(measures)):\n",
    "    avg = avg + measures[i]\n",
    "avg/len(measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rus-Eng Pairs\n",
      "\n",
      "gd-rkvdstv\n",
      "prps-tsl\n",
      "prncpl-prntsp\n",
      "chrtr-stv\n",
      "nt-nts\n",
      "ntns-vyrzh\n",
      "xprss-chstnst\n",
      "prtclr-vyrzh\n",
      "nd-chstnst\n",
      "chv-nbkhdm\n",
      "ntrn-dstzhn\n",
      "cpr-mzhdnrdn\n",
      "prmt-strdnchstv\n",
      "ncrg-pshchrn\n",
      "hmn-pshchrn\n",
      "rspct-vzhn\n",
      "rght-prv\n",
      "fndmnt-chlvk\n",
      "wtht-snvn\n",
      "\n",
      "\n",
      "English consonants\n",
      "\n",
      "['gd', 'prps', 'prncpl', 'chrtr', 'nt', 'ntns', 'xprss', 'prtclr', 'nd', 'chv', 'ntrn', 'cpr', 'prmt', 'ncrg', 'rspct', 'hmn', 'rght', 'fndmnt', 'frdm', 'wtht', 'dstnct']\n",
      "\n",
      "\n",
      "Russian consonants\n",
      "\n",
      "['rkvdstv', 'tsl', 'prntsp', 'stv', 'rgnzts', \"b'dnn\", 'nts', 'vyrzh', 'chstnst', 'nbkhdm', 'dstzhn', 'mzhdnrdn', 'strdnchstv', 'pshchrn', 'pshchrn', 'vzhn', 'prv', 'chlvk', 'snvn', 'svbd', 'rzlch']\n",
      "\n",
      "\n",
      "L-Distance measures per pair of aligned words\n",
      "\n",
      "[0.14285714285714285, 0.0, 0.5, 0.2, 0.6666666666666666, 0.0, 0.14285714285714285, 0.0, 0.14285714285714285, 0.16666666666666666, 0.3333333333333333, 0.125, 0.2, 0.2857142857142857, 0.2857142857142857, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "Average\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.16798245614035087"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Russian and English\n",
    "from transliterate import translit, get_available_language_codes\n",
    "import nltk\n",
    "import re\n",
    "engSample = \"Guided by the purposes and principles of the Charter of the United Nations, and expressing in particular the need to achieve international cooperation in promoting and encouraging respect for human rights and fundamental freedoms for all without distinction\"\n",
    "rusSample = \"Руководствуясь целями и принципами Устава Организации Объединенных Наций и выражая в частности необходимость достижения международного сотрудничества в поощрении и поощрении уважения прав человека и основных свобод для всех без различия\"\n",
    "#rusSample = translit(rusSample, 'ru', reversed=True)\n",
    "engWords = engSample.split()\n",
    "rusWords = rusSample.split()\n",
    "\n",
    "#Removing vowels, punctuation, stemming\n",
    "engWords = clean_sample(engSample, \"english\")\n",
    "rusWords = clean_sample(rusSample, \"russian\")\n",
    "\n",
    "\n",
    "# transliterating Cyrillic text\n",
    "print(\"Rus-Eng Pairs\\n\")\n",
    "translitRus=[]\n",
    "for i in range(len(rusWords)):\n",
    "    l = translit(rusWords[i], 'ru', reversed=True)\n",
    "    translitRus.append(l)\n",
    "\n",
    "# running through clean_sample once more - to remove vowels\n",
    "translitString=\"\"\n",
    "for i in range(len(translitRus)):\n",
    "    translitString+=translitRus[i] + \" \"\n",
    "rusFinal = clean_sample(translitString, \"russian\")\n",
    "    \n",
    "# manual alignment\n",
    "eng_rus_align = [(0,0), (1,1), (2,2), (3,3), (4,6), (5,7), (6,8), (7,7), (8,8), (9,9), (10, 10), (11,11), (12,12), (13,13), (15,14), (14,15), (16,16), (17,17), (19,18)]\n",
    "\n",
    "#Passing lists of consonant-only words in both languages and their alignment to Ldistnance method\n",
    "measures = measure_samples(engWords, rusFinal, eng_rus_align)\n",
    "print(\"\\n\")\n",
    "print(\"English consonants\\n\")\n",
    "print(engWords)\n",
    "print(\"\\n\")\n",
    "print(\"Russian consonants\\n\")\n",
    "print(rusFinal)\n",
    "print(\"\\n\")\n",
    "print(\"L-Distance measures per pair of aligned words\\n\")\n",
    "print(measures)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Average\")\n",
    "avg = 0\n",
    "for i in range(len(measures)):\n",
    "    avg = avg + measures[i]\n",
    "avg/len(measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fra-Eng Pairs\n",
      "\n",
      "gd-g\n",
      "prps-bt\n",
      "prncpl-prncp\n",
      "chrtr-chrt\n",
      "nt-ns\n",
      "ntns-ntn\n",
      "xprss-xprm\n",
      "prtclr-prtc\n",
      "nd-ncss\n",
      "chv-rs\n",
      "ntrn-ntrntn\n",
      "cpr-cpr\n",
      "prmt-prmvr\n",
      "ncrg-ncrg\n",
      "rspct-rspct\n",
      "hmn-hmm\n",
      "rght-rt\n",
      "fndmnt-fnmnt\n",
      "frdm-brt\n",
      "wtht-sn\n",
      "dstnct-stnct\n",
      "\n",
      "\n",
      "English consonants\n",
      "\n",
      "['gd', 'prps', 'prncpl', 'chrtr', 'nt', 'ntns', 'xprss', 'prtclr', 'nd', 'chv', 'ntrn', 'cpr', 'prmt', 'ncrg', 'rspct', 'hmn', 'rght', 'fndmnt', 'frdm', 'wtht', 'dstnct']\n",
      "\n",
      "\n",
      "French consonants\n",
      "\n",
      "['g', 'bt', 'prncp', 'nnc', 'chrt', 'ntn', 'ns', 'xprm', 'prtc', 'ncss', 'rs', 'cpr', 'ntrntn', 'v', 'prmvr', 'ncrg', 'rspct', 'rt', 'hmm', 'brt', 'fnmnt', 'ts', 'sn', 'stnct']\n",
      "\n",
      "\n",
      "L-Distance measures per pair of aligned words\n",
      "\n",
      "[0.5, 0.0, 0.8333333333333334, 0.8, 0.5, 0.75, 0.6, 0.6666666666666666, 0.25, 0.0, 0.6666666666666666, 1.0, 0.6, 1.0, 1.0, 0.6666666666666666, 0.5, 0.8333333333333334, 0.25, 0.0, 0.8333333333333334]\n",
      "\n",
      "\n",
      "Average\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5833333333333334"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#French and English\n",
    "import nltk\n",
    "engSample = \"Guided by the purposes and principles of the Charter of the United Nations, and expressing in particular the need to achieve international cooperation in promoting and encouraging respect for human rights and fundamental freedoms for all without distinction\"\n",
    "fraSample = \"Guidée par les buts et principes énoncés dans la Charte des Nations Unies, et exprimant en particulier la nécessité de réaliser la coopération internationale en vue de promouvoir et d'encourager le respect des droits de l'homme et des libertés fondamentales pour tous sans distinction\"\n",
    "#Removing vowels, punctuation, stemming\n",
    "engWords = clean_sample(engSample, \"english\")\n",
    "fraWords = clean_sample(fraSample, \"french\")\n",
    "\n",
    "#Manually transcribing sentence alignment to compare word-to-word\n",
    "print(\"Fra-Eng Pairs\\n\")\n",
    "eng_fra_align = [(0,0), (1,1), (2,2), (3,4), (4,6), (5,5), (6,7), (7,8), (8,9), (9, 10), (10, 12), (11,11), (12, 14), (13, 15), (14, 16), (15, 18), (16, 17), (17, 20), (18, 19), (19, 22), (20, 23)]\n",
    "\n",
    "#Passing lists of consonant-only words in both languages and their alignment to Ldistnance method\n",
    "measures = measure_samples(engWords, fraWords, eng_fra_align)\n",
    "print(\"\\n\")\n",
    "print(\"English consonants\\n\")\n",
    "print(engWords)\n",
    "print(\"\\n\")\n",
    "print(\"French consonants\\n\")\n",
    "print(fraWords)\n",
    "print(\"\\n\")\n",
    "print(\"L-Distance measures per pair of aligned words\\n\")\n",
    "print(measures)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Average\")\n",
    "avg = 0\n",
    "for i in range(len(measures)):\n",
    "    avg = avg + measures[i]\n",
    "avg/len(measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eng-Ger Pairs\n",
      "\n",
      "swt-txtnt\n",
      "brnknft-grmnt\n",
      "n-nw\n",
      "mtgldstt-mmbrstt\n",
      "nrst-nhnd\n",
      "drttlnd-thrdcntr\n",
      "ndrrst-thr\n",
      "pflcht-blg\n",
      "vrfss-cnsttt\n",
      "nsbsnd-prtclr\n",
      "prtkll-prtcl\n",
      "vrnbr-cmpt\n",
      "trff-tk\n",
      "n-nw\n",
      "mtgldstt-mmbrstt\n",
      "ggnt-pprpr\n",
      "mssnhmn-stp\n",
      "fstgstllt-stblshd\n",
      "nvrnbr-ncmpt\n",
      "bstgn-lmn\n",
      "\n",
      "\n",
      "German consonants\n",
      "\n",
      "['swt', 'brnknft', 'mhr', 'n', 'mtgldstt', 'nrst', 'mhr', 'drttlnd', 'ndrrst', 'pflcht', 'vrfss', 'nsbsnd', 'prtkll', 'vrnbr', 'snd', 'trff', 'n', 'mtgldstt', 'ggnt', 'mssnhmn', 'fstgstllt', 'nvrnbr', 'bstgn']\n",
      "\n",
      "\n",
      "English consonants\n",
      "\n",
      "['t', 'xtnt', 'grmnt', 'n', 'nw', 'mmbr', 'stt', 'n', 'hnd', 'n', 'thrd', 'cntr', 'thr', 'cmpt', 'blg', 'rs', 'cnsttt', 'prtclr', 'prtcl', 'nw', 'mmbr', 'stt', 'shll', 'tk', 'pprpr', 'stp', 'lmn', 'ncmpt', 'stblshd']\n",
      "\n",
      "\n",
      "L-Distance measures per pair of aligned words\n",
      "\n",
      "[0.2, 0.42857142857142855, 0.5, 0.5, 0.25, 0.125, 0.16666666666666666, 0.16666666666666666, 0.0, 0.0, 0.6666666666666666, 0.0, 0.25, 0.5, 0.5, 0.0, 0.14285714285714285, 0.2222222222222222, 0.16666666666666666, 0.2]\n",
      "\n",
      "\n",
      "Average\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.24926587301587305"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gerSample = \"Soweit Übereinkünfte zwischen einem oder mehreren neuen Mitgliedstaaten einerseits und einem oder mehreren Drittländern andererseits nicht mit den Pflichten aus der Verfassung und insbesondere aus diesem Protokoll vereinbar sind, treffen die neuen Mitgliedstaaten die geeigneten Maßnahmen, um die festgestellten Unvereinbarkeiten zu beseitigen.\"\n",
    "engSample = \"To the extent that agreements between one or more of the new Member States on the one hand, and one or more third countries on the other, are not compatible with the obligations arising from the Constitution and in particular from this Protocol, the new Member States shall take all appropriate steps to eliminate the incompatibilities established.\"\n",
    "gerWords = clean_sample(gerSample, \"german\")\n",
    "engWords = clean_sample(engSample, \"english\")\n",
    "\n",
    "#Manually transcribing sentence alignment to compare word-to-word\n",
    "print(\"Eng-Ger Pairs\\n\")\n",
    "#german first, then english\n",
    "#Using dictionary for many-to-many comparisons\n",
    "ger_eng_dict = {\n",
    "    \"0\": [0,1],\n",
    "    \"1\": [2],\n",
    "    \"3\": [4],\n",
    "    \"4\": [5,6],\n",
    "    \"5\": [7,8],\n",
    "    \"7\": [10,11],\n",
    "    \"8\": [12],\n",
    "    \"9\": [14],\n",
    "    \"10\":[16],\n",
    "    \"11\":[17],\n",
    "    \"12\":[18],\n",
    "    \"13\":[13],\n",
    "    \"15\":[23],\n",
    "    \"16\":[19],\n",
    "    \"17\":[20,21],\n",
    "    \"18\":[24],\n",
    "    \"19\":[25],\n",
    "    \"20\":[28],\n",
    "    \"21\":[27],\n",
    "    \"22\":[26]\n",
    "}\n",
    "\n",
    "measures = measure_samples_dict(gerWords, engWords, ger_eng_dict)\n",
    "print(\"\\n\")\n",
    "print(\"German consonants\\n\")\n",
    "print(gerWords)\n",
    "print(\"\\n\")\n",
    "print(\"English consonants\\n\")\n",
    "print(engWords)\n",
    "print(\"\\n\")\n",
    "print(\"L-Distance measures per pair of aligned words\\n\")\n",
    "print(measures)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Average\")\n",
    "avg = 0\n",
    "for i in range(len(measures)):\n",
    "    avg = avg + measures[i]\n",
    "avg/len(measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h*A AlbrnAmj yETynA nTq AlHrwf\n"
     ]
    }
   ],
   "source": [
    "import lang_trans\n",
    "from lang_trans.arabic import buckwalter\n",
    "print(buckwalter.transliterate(u'هذا البرنامج يعطينا نطق الحروف'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inspir nspr\n",
      "proposit prpst\n",
      "principi prncp\n",
      "cart crt\n",
      "nacion ncn\n",
      "unid nd\n",
      "expres xprs\n",
      "particul prtcl\n",
      "neces ncs\n",
      "logr lgr\n",
      "cooper cpr\n",
      "internacional ntrncnl\n",
      "promocion prmcn\n",
      "foment fmnt\n",
      "respet rspt\n",
      "derech drch\n",
      "human hmn\n",
      "libertad lbrtd\n",
      "fundamental fndmntl\n",
      "distincion dstncn\n",
      "guid g\n",
      "but bt\n",
      "princip prncp\n",
      "enonc nnc\n",
      "chart chrt\n",
      "nation ntn\n",
      "unies, ns\n",
      "exprim xprm\n",
      "particuli prtc\n",
      "necess ncss\n",
      "realis rs\n",
      "cooper cpr\n",
      "international ntrntn\n",
      "vu v\n",
      "promouvoir prmvr\n",
      "d'encourag ncrg\n",
      "respect rspct\n",
      "droit rt\n",
      "l'homm hmm\n",
      "libert brt\n",
      "fondamental fnmnt\n",
      "tous ts\n",
      "san sn\n",
      "distinct stnct\n",
      "Spa-Fra Pairs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Spanish and French\n",
    "import nltk\n",
    "spaSample = \"Inspirándose en los propósitos y principios de la Carta de las Naciones Unidas y expresando en particular la necesidad de lograr la cooperación internacional en la promoción y el fomento del respeto de los derechos humanos y las libertades fundamentales para todos sin distinción\"\n",
    "fraSample = \"Guidée par les buts et principes énoncés dans la Charte des Nations Unies, et exprimant en particulier la nécessité de réaliser la coopération internationale en vue de promouvoir et d'encourager le respect des droits de l'homme et des libertés fondamentales pour tous sans distinction\"\n",
    "#Removing vowels, punctuation, stemming\n",
    "spaWords = clean_sample(spaSample, \"spanish\")\n",
    "fraWords = clean_sample(fraSample, \"french\")\n",
    "\n",
    "#Manually transcribing sentence alignment to compare word-to-word\n",
    "print(\"Spa-Fra Pairs\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
