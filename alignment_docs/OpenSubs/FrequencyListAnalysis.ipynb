{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5acb5994",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import pandas as pd\n",
    "from LDistance import LDistance as LDistance\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aac634e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringDevowelize(strArg):\n",
    "    strRet = \"\"\n",
    "    listVowels = ['a', 'e', 'i', 'o', 'u']\n",
    "    for n in strArg:\n",
    "        if n not in listVowels:\n",
    "            strRet += n\n",
    "    return strRet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "533d4de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def csvFreqListLDistances(strSrcLangFile, strSrcLang, strTarLang, strSrcLangCode, strTarLangCode):\n",
    "    # Creates file from frequency list\n",
    "    fileFreqList = open(strSrcLangFile, encoding=\"utf-8\")\n",
    "    listStops = stopwords.words(strSrcLang)\n",
    "    listAllLines = fileFreqList.readlines()\n",
    "\n",
    "    # listFirstThousand is the first thousand non-stopword entries in the file\n",
    "    listFirstThousand = []\n",
    "\n",
    "    # scrapes frequency list for first 1000 entries (word and frequency) not in stopwords\n",
    "    intFreqIndex = 0\n",
    "    while len(listFirstThousand) < 1000:\n",
    "\n",
    "        # checks if word is a stop word and adds if it is not\n",
    "        if re.split(\" \", listAllLines[intFreqIndex])[0].lower() not in listStops:\n",
    "            listFirstThousand.append(listAllLines[intFreqIndex].lower())\n",
    "        intFreqIndex += 1\n",
    "    listThousandWords = []\n",
    "\n",
    "    # removes frequency from entries and adds just the word to listThousandWords\n",
    "    for stringText in listFirstThousand:\n",
    "        listLine = re.split(\" \", stringText)\n",
    "        listThousandWords.append(listLine[0])\n",
    "\n",
    "    # list of length 2 lists with the words from language A and their translations into language B\n",
    "    listSrcTarWordLists = []\n",
    "    for wordA in listThousandWords:\n",
    "        listSrcTarWordLists.append([wordA, GoogleTranslator(source=strSrcLangCode, target=strTarLangCode).translate(text=wordA).lower()])\n",
    "    listLDists = []\n",
    "    for i in range(len(listSrcTarWordLists)):\n",
    "        strAWord = listSrcTarWordLists[i][0].lower()\n",
    "        strBWord = listSrcTarWordLists[i][1].lower()\n",
    "        listLDists.append(LDistance.floatLDistance(LDistance, stringDevowelize(strAWord), stringDevowelize(strBWord)))\n",
    "\n",
    "    # creates dataframe with columns: original word, translation, and l-distance\n",
    "    df = pd.DataFrame(listSrcTarWordLists, columns=[strSrcLang, strTarLang])\n",
    "    df[\"Distances\"] = listLDists\n",
    "    print(df)\n",
    "    csvFileName = \"\"\n",
    "    csvFileName += strSrcLang[0:3]\n",
    "    csvFileName += strTarLang[0:3]\n",
    "    csvFileName += \"1.csv\"\n",
    "\n",
    "    df.to_csv(csvFileName, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef1d953f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def snsCreateHeatMap(listRatioValues, listLangNames, strFileSaveName):\n",
    "    intTableLen = pow(len(listLangNames), 2)\n",
    "    \n",
    "    if ((len(listRatioValues[0]) * len(listRatioValues)) != intTableLen):\n",
    "        return \"Incorrect number of data values, please edit listRatioValues.\"\n",
    "    \n",
    "    listData = listRatioValues\n",
    "    listRows = listLangNames\n",
    "    listCols = listLangNames\n",
    "\n",
    "    df = pd.DataFrame(listData, index=listRows, columns=listCols)\n",
    "    s = sns.heatmap(df.head(), annot=True, cmap='YlOrRd', cbar=True,fmt='.4f')\n",
    "    plt.savefig(strFileSaveName)\n",
    "    s.set(xlabel='Source Language', ylabel='Target Language')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f81dd2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      English    Spanish  Distances\n",
      "0        know      saber   0.000000\n",
      "1        like   me gusta   0.000000\n",
      "2         get    obtener   0.250000\n",
      "3          go      vamos   0.000000\n",
      "4       right   correcto   0.400000\n",
      "..        ...        ...        ...\n",
      "995  drinking   bebiendo   0.166667\n",
      "996     grand  grandioso   0.800000\n",
      "997     worst    el peor   0.000000\n",
      "998     match      juego   0.000000\n",
      "999   nervous   nervioso   1.000000\n",
      "\n",
      "[1000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "dfEngSpa = csvFreqListLDistances(\"./freq_samples/en_50k.txt\", \"English\", \"Spanish\", \"en\", \"es\")\n",
    "dfEngSpa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
