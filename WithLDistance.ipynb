{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate l-distance between two strings\n",
    "# accepts two string parameters: \n",
    "def ldistance(strA, strB):\n",
    "    import numpy as np # to create matrix\n",
    "    \n",
    "    a = 0\n",
    "    b = 0\n",
    "    c = 0\n",
    "    \n",
    "    #setting up matrix\n",
    "    size_x = len(strA) + 1\n",
    "    size_y = len(strB) + 1\n",
    "    matrix = np.zeros((size_x, size_y))\n",
    "    for x in range(size_x):\n",
    "        matrix [x, 0] = x\n",
    "    for y in range(size_y):\n",
    "        matrix [0, y] = y\n",
    "    \n",
    "    #populating matrix\n",
    "    for x in range(1, size_x):\n",
    "        for y in range(1, size_y):\n",
    "            if strA[x-1] == strB[y-1]: #elements are equal\n",
    "                matrix[x][y] = matrix[x-1][y-1]\n",
    "            else: \n",
    "                a = matrix[x][y-1]\n",
    "                b = matrix[x-1][y]\n",
    "                c = matrix[x-1][y-1]\n",
    "                if (a <= b and a <= c):\n",
    "                    matrix[x][y] = a + 1\n",
    "                elif (b <= a and b <= c):\n",
    "                    matrix[x][y] = b + 1\n",
    "                else:\n",
    "                    matrix[x][y] = c + 1\n",
    "        \n",
    "\n",
    "                    \n",
    "    # bottom-right element is l-distance\n",
    "    distance = matrix[-1][-1]\n",
    "    \n",
    "    # printing\n",
    "    #for t1 in range(size_x):\n",
    "        #for t2 in range(size_y ):\n",
    "            #print(int(matrix[t1][t2]), end=\" \")\n",
    "        #print()\n",
    "        \n",
    "    #taking into consideration the length of the words\n",
    "    length = 0\n",
    "    if ((len(strA) > len(strB)) or (len(strA) == len(strB))):\n",
    "        length = len(strA)\n",
    "    else:\n",
    "        length = len(strB)\n",
    "        \n",
    "    lscore = ((length - distance) / length) \n",
    "    \n",
    "    return lscore\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove vowels, common words, numbers, and punctuation, as well as stem the words\n",
    "# accepts 2 parameters: string for sample and string for language\n",
    "def clean_sample(sample, language):\n",
    "    import nltk \n",
    "    import re # to use in regular expressions\n",
    "    from nltk.stem.snowball import SnowballStemmer # to stem words, doesn't work well\n",
    "    from nltk.corpus import stopwords # to remove common words\n",
    "    \n",
    "    # creating objects for stemmer, common words and key for punctuation/numbers to be removed\n",
    "    stemmer = SnowballStemmer(str(language))\n",
    "    common_words = stopwords.words(language)\n",
    "    toRemove = re.compile(r\"[aeiou0-9,@\\?\\.$%_/:()]\")\n",
    "\n",
    "    # separates sentence into elements and stores in elemList\n",
    "    elemList=sample.split()\n",
    "    \n",
    "    # stemming first\n",
    "    stems=[]\n",
    "    for elem in elemList:\n",
    "        if elem not in common_words:\n",
    "            w = stemmer.stem(elem)\n",
    "            stems.append(w)\n",
    "\n",
    "    #now removing punctuation, numbers, vowels and storing in wordList\n",
    "    wordList=[]\n",
    "    for i in stems:\n",
    "        s = i\n",
    "        elem = re.sub(toRemove, \"\", s.lower())\n",
    "        wordList.append(elem)\n",
    "    \n",
    "    # stems words and appends them to list to be returned\n",
    "    return wordList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that lines up pairs of words between the two samples, and calculates their l-distance\n",
    "# parameters: 2 lists of words from each sample, 1 list of manually-created alignment between the two lists\n",
    "def measure_samples(list1, list2, alignment):\n",
    "    distances=[]\n",
    "    \n",
    "    # aligning pairs\n",
    "    for i in range(len(alignment)):\n",
    "        idx1 = alignment[i][0]\n",
    "        idx2 = alignment[i][1]\n",
    "        str1 = list1[idx1]\n",
    "        str2 = list2[idx2]\n",
    "        print(str1 + \"-\" + str2)\n",
    "        l = ldistance(str(str1), str(str2))\n",
    "        distances.append(l)\n",
    "        \n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spa-Eng Pairs\n",
      "\n",
      "gd-g\n",
      "prps-prpst\n",
      "prncpl-prncp\n",
      "chrtr-crt\n",
      "nt-ncn\n",
      "ntns-nds\n",
      "xprss-xprs\n",
      "prtclr-prtcl\n",
      "nd-ncs\n",
      "chv-cpr\n",
      "ntrn-lgr\n",
      "cpr-ntrncnl\n",
      "prmt-prmv\n",
      "ncrg-lnt\n",
      "rspct-drch\n",
      "hmn-rspt\n",
      "rght-lbrtd\n",
      "fndmnt-hmn\n",
      "wtht-fndmntl\n",
      "\n",
      "\n",
      "English consonants\n",
      "\n",
      "['gd', 'prps', 'prncpl', 'chrtr', 'nt', 'ntns', 'xprss', 'prtclr', 'nd', 'chv', 'ntrn', 'cpr', 'prmt', 'ncrg', 'rspct', 'hmn', 'rght', 'fndmnt', 'frdm', 'wtht', 'dstnct']\n",
      "\n",
      "\n",
      "Spanish consonants\n",
      "\n",
      "['g', 'prpst', 'prncp', 'crt', 'ncn', 'nds', 'xprs', 'prtcl', 'ncs', 'lgr', 'cpr', 'ntrncnl', 'prmv', 'lnt', 'rspt', 'drch', 'hmn', 'lbrtd', 'fndmntl', 'dstncn']\n",
      "\n",
      "\n",
      "L-Distance measures per pair of aligned words\n",
      "\n",
      "[0.5, 0.8, 0.8333333333333334, 0.6, 0.3333333333333333, 0.5, 0.8, 0.8333333333333334, 0.3333333333333333, 0.3333333333333333, 0.25, 0.14285714285714285, 0.75, 0.0, 0.2, 0.0, 0.2, 0.3333333333333333, 0.14285714285714285]\n",
      "\n",
      "\n",
      "Average\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4150375939849624"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.translate import Alignment\n",
    "engSample = \"Guided by the purposes and principles of the Charter of the United Nations, and expressing in particular the need to achieve international cooperation in promoting and encouraging respect for human rights and fundamental freedoms for all without distinction\"\n",
    "spaSample = \"Guiado por los propósitos y principios de la Carta de las Naciones Unidas, y expresando en particular la necesidad de lograr la cooperación internacional para promover y alentar el respeto de los derechos humanos y las libertades fundamentales para todos sin distinción\"\n",
    "\n",
    "#Removing vowels, punctuation, stemming\n",
    "engWords = clean_sample(engSample, \"english\")\n",
    "spaWords = clean_sample(spaSample, \"spanish\")\n",
    "\n",
    "#Manually transcribing sentence alignment to compare word-to-word\n",
    "print(\"Spa-Eng Pairs\\n\")\n",
    "eng_spa_align = [(0,0), (1,1), (2,2), (3,3), (4,4), (5,5), (6,6), (7,7), (8,8), (9, 10), (10, 9), (11,11), (12, 12), (13, 13), (14, 15), (15, 14), (16, 17), (17, 16), (19, 18)]\n",
    "\n",
    "\n",
    "#Passing lists of consonant-only words in both languages and their alignment to Ldistnance method\n",
    "measures = measure_samples(engWords, spaWords, eng_spa_align)\n",
    "print(\"\\n\")\n",
    "print(\"English consonants\\n\")\n",
    "print(engWords)\n",
    "print(\"\\n\")\n",
    "print(\"Spanish consonants\\n\")\n",
    "print(spaWords)\n",
    "print(\"\\n\")\n",
    "print(\"L-Distance measures per pair of aligned words\\n\")\n",
    "print(measures)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Average\")\n",
    "avg = 0\n",
    "for i in range(len(measures)):\n",
    "    avg = avg + measures[i]\n",
    "avg/len(measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rus-Eng Pairs\n",
      "\n",
      "gd-rkvdstv\n",
      "prps-tsl\n",
      "prncpl-prntsp\n",
      "chrtr-stv\n",
      "nt-nts\n",
      "ntns-vyrzh\n",
      "xprss-chstnst\n",
      "prtclr-vyrzh\n",
      "nd-chstnst\n",
      "chv-nbhdm\n",
      "ntrn-dstzhn\n",
      "cpr-mzhdnrdn\n",
      "prmt-strdnchstv\n",
      "ncrg-pschrn\n",
      "hmn-pschrn\n",
      "rspct-vzhn\n",
      "rght-prv\n",
      "fndmnt-chlvk\n",
      "wtht-snvn\n",
      "\n",
      "\n",
      "English consonants\n",
      "\n",
      "['gd', 'prps', 'prncpl', 'chrtr', 'nt', 'ntns', 'xprss', 'prtclr', 'nd', 'chv', 'ntrn', 'cpr', 'prmt', 'ncrg', 'rspct', 'hmn', 'rght', 'fndmnt', 'frdm', 'wtht', 'dstnct']\n",
      "\n",
      "\n",
      "Russian consonants\n",
      "\n",
      "['rkvdstv', 'tsl', 'prntsp', 'stv', 'rgnzts', \"b'dnn\", 'nts', 'vyrzh', 'chstnst', 'nbhdm', 'dstzhn', 'mzhdnrdn', 'strdnchstv', 'pschrn', 'pschrn', 'vzhn', 'prv', 'chlvk', 'snvn', 'svbd', 'rzlch']\n",
      "\n",
      "\n",
      "L-Distance measures per pair of aligned words\n",
      "\n",
      "[0.14285714285714285, 0.0, 0.5, 0.2, 0.6666666666666666, 0.0, 0.14285714285714285, 0.0, 0.14285714285714285, 0.2, 0.3333333333333333, 0.125, 0.2, 0.3333333333333333, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0]\n",
      "\n",
      "\n",
      "Average\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.17474937343358396"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transliterate import translit, get_available_language_codes\n",
    "import nltk\n",
    "import re\n",
    "from nltk.translate import Alignment\n",
    "engSample = \"Guided by the purposes and principles of the Charter of the United Nations, and expressing in particular the need to achieve international cooperation in promoting and encouraging respect for human rights and fundamental freedoms for all without distinction\"\n",
    "rusSample = \"Руководствуясь целями и принципами Устава Организации Объединенных Наций и выражая в частности необходимость достижения международного сотрудничества в поощрении и поощрении уважения прав человека и основных свобод для всех без различия\"\n",
    "#rusSample = translit(rusSample, 'ru', reversed=True)\n",
    "engWords = engSample.split()\n",
    "rusWords = rusSample.split()\n",
    "\n",
    "#Removing vowels, punctuation, stemming\n",
    "engWords = clean_sample(engSample, \"english\")\n",
    "rusWords = clean_sample(rusSample, \"russian\")\n",
    "\n",
    "\n",
    "# transliterating Cyrillic text\n",
    "print(\"Rus-Eng Pairs\\n\")\n",
    "translitRus=[]\n",
    "for i in range(len(rusWords)):\n",
    "    l = translit(rusWords[i], 'ru', reversed=True)\n",
    "    translitRus.append(l)\n",
    "\n",
    "# running through clean_sample once more - to remove vowels\n",
    "translitString=\"\"\n",
    "for i in range(len(translitRus)):\n",
    "    translitString+=translitRus[i] + \" \"\n",
    "rusFinal = clean_sample(translitString, \"russian\")\n",
    "    \n",
    "# manual alignment\n",
    "eng_rus_align = [(0,0), (1,1), (2,2), (3,3), (4,6), (5,7), (6,8), (7,7), (8,8), (9,9), (10, 10), (11,11), (12,12), (13,13), (15,14), (14,15), (16,16), (17,17), (19,18)]\n",
    "\n",
    "#Passing lists of consonant-only words in both languages and their alignment to Ldistnance method\n",
    "measures = measure_samples(engWords, rusFinal, eng_rus_align)\n",
    "print(\"\\n\")\n",
    "print(\"English consonants\\n\")\n",
    "print(engWords)\n",
    "print(\"\\n\")\n",
    "print(\"Russian consonants\\n\")\n",
    "print(rusFinal)\n",
    "print(\"\\n\")\n",
    "print(\"L-Distance measures per pair of aligned words\\n\")\n",
    "print(measures)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Average\")\n",
    "avg = 0\n",
    "for i in range(len(measures)):\n",
    "    avg = avg + measures[i]\n",
    "avg/len(measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use to implement bags method\n",
    "import nltk\n",
    "from nltk.translate import Alignment\n",
    "engSample = \"Guided by the purposes and principles of the Charter of the United Nations, and expressing in particular the need to achieve international cooperation in promoting and encouraging respect for human rights and fundamental freedoms for all without distinction\"\n",
    "spaSample = \"Guiado por los propósitos y principios de la Carta de las Naciones Unidas, y expresando en particular la necesidad de lograr la cooperación internacional para promover y alentar el respeto de los derechos humanos y las libertades fundamentales para todos sin distinción\"\n",
    "engWords = clean_sample(engSample, \"english\")\n",
    "spaWords = clean_sample(spaSample, \"spanish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rus-Eng Pairs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use to implement bags method\n",
    "from transliterate import translit, get_available_language_codes\n",
    "import nltk\n",
    "from nltk.translate import Alignment\n",
    "engSample = \"Guided by the purposes and principles of the Charter of the United Nations, and expressing in particular the need to achieve international cooperation in promoting and encouraging respect for human rights and fundamental freedoms for all without distinction\"\n",
    "rusSample = \"Руководствуясь целями и принципами Устава Организации Объединенных Наций и выражая, в частности, необходимость достижения международного сотрудничества в поощрении и поощрении уважения прав человека и основных свобод для всех без различия\"\n",
    "\n",
    "#Removing vowels, punctuation, stemming\n",
    "engWords = clean_sample(engSample, \"english\")\n",
    "rusWords = clean_sample(rusSample, \"russian\")\n",
    "\n",
    "# transliterating Cyrillic text\n",
    "print(\"Rus-Eng Pairs\\n\")\n",
    "translitRus=[]\n",
    "for i in range(len(rusWords)):\n",
    "    l = translit(rusWords[i], 'ru', reversed=True)\n",
    "    translitRus.append(l)\n",
    "\n",
    "# running through clean_sample once more - to remove vowels\n",
    "translitString=\"\"\n",
    "for i in range(len(translitRus)):\n",
    "    translitString+=translitRus[i] + \" \"\n",
    "rusFinal = clean_sample(translitString, \"russian\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
